{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Leit989ghwi",
        "outputId": "808c2d8d-8319-45f0-e195-4389a945aad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install opencc-python-reimplemented\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOo9VFpejNnJ",
        "outputId": "11db068c-ec2d-41fb-dcc0-482c420365f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.8 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencc-python-reimplemented\n",
            "  Downloading opencc_python_reimplemented-0.1.7-py2.py3-none-any.whl (481 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.8/481.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencc-python-reimplemented\n",
            "Successfully installed opencc-python-reimplemented-0.1.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "path = r\"/content/drive/MyDrive/CSD_dataset.xlsx\"\n",
        "df = pd.read_excel(path)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "PrwpNdEK2VG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "openai.api_key = \"your-api-key\"\n",
        "openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=\"Say this is a test\",\n",
        "  max_tokens=5,\n",
        "  temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "CDR5Ds_S9V9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from opencc import OpenCC\n",
        "cc = OpenCC('s2hk')\n",
        "text = 'PLACEHOLDER'\n",
        "prompt = \"判断这条文本对疫苗的立场是支持，反对，或者其他。\\n文本：\" + text + \"\\n立场：\"\n",
        "prompt = cc.convert(prompt)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "S7sviu7TYMh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from opencc import OpenCC\n",
        "cc = OpenCC('s2hk')\n",
        "idx =100\n",
        "text = df['text'].iloc[idx]\n",
        "prompt = \"判断这条文本对疫苗的立场是支持，反对，或者其他。\\n文本：\" + text + \"\\n立场：\"\n",
        "prompt = cc.convert(prompt)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "k9-Mv2T-1QjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "df = df2\n",
        "\n",
        "df['chatgpt_label'] = ''\n",
        "for i in tqdm(range(len(df))):\n",
        "  text = df['text'].iloc[i]\n",
        "  prompt = \"判断这条文本对疫苗的立场是支持，反对，或者其他。\\n文本：\" + text + \"\\n立场：\"\n",
        "  prompt = cc.convert(prompt)\n",
        "  try:\n",
        "      result = openai.Completion.create(\n",
        "              model=\"text-davinci-003\",\n",
        "              prompt = prompt,\n",
        "              max_tokens = 5,\n",
        "              temperature=0)\n",
        "  except:\n",
        "      time.sleep(1)\n",
        "      result = openai.Completion.create(\n",
        "      model=\"text-davinci-003\",\n",
        "      prompt = prompt,\n",
        "      max_tokens = 5,\n",
        "      temperature=0)\n",
        "  result = result[\"choices\"][0][\"text\"].strip()\n",
        "  df['chatgpt_label'].iloc[i] = result"
      ],
      "metadata": {
        "id": "iS68f7nc3-xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel(\"resultgbt.xlsx\", index = None)"
      ],
      "metadata": {
        "id": "k-0R1PRI8qsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df =pd.read_excel(\"resultgbt.xlsx\")"
      ],
      "metadata": {
        "id": "olJDRAl0Ux3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['chatgpt_label'].value_counts()"
      ],
      "metadata": {
        "id": "Cv0MhVz2T7ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['chatgpt_label'] = df['chatgpt_label'].map({'其他':2, '支': 0, '反对':1, '其他。':2})\n",
        "df['chatgpt_label'].value_counts()"
      ],
      "metadata": {
        "id": "PyGMmnY2UAQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1s = []\n",
        "for i in range(100):\n",
        "  test = df.sample(frac = 0.2, random_state = i)\n",
        "  labels = test.label.to_list()\n",
        "  preds = test.chatgpt_label.to_list()\n",
        "  y_true = labels\n",
        "  y_pred = preds\n",
        "  f1 = f1_score(y_true, y_pred, average='macro')\n",
        "  f1s.append(f1)\n",
        "\n",
        "a_mean = np.mean(f1s)\n",
        "a_std = np.std(f1s,ddof=1)\n",
        "\n",
        "print(\"MEAN:\", a_mean)\n",
        "print(\"STD:\", a_std)\n",
        "print()"
      ],
      "metadata": {
        "id": "ZyJHc1JPTbUy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}